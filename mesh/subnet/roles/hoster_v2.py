import asyncio
import hashlib
import io
import secrets
import threading
from typing import Optional, Tuple

import torch

from mesh import DHT, get_dht_time
from mesh.dht.validation import RecordValidatorBase
from mesh.subnet.protocols.inference_protocol import InferenceProtocol
from mesh.subnet.utils.consensus import MAX_HOSTER_COMMIT_TIME, MAX_HOSTER_REVEAL_TIME, get_consensus_key
from mesh.subnet.utils.hoster import (
    get_hoster_commit_key,
    get_hoster_reveal_key,
    get_hoster_subkey_rsa,
)
from mesh.subnet.utils.key import extract_rsa_peer_id
from mesh.substrate.chain_functions_v2 import Hypertensor
from mesh.substrate.config import BLOCK_SECS
from mesh.substrate.utils import get_epoch_progress
from mesh.utils.logging import get_logger

logger = get_logger(__name__)

# We remove 60 seconds off of the max expiration in case another node gets it late
# Max discrepency in DHT times is about 4 seconds.
_max_hoster_commit_time = MAX_HOSTER_COMMIT_TIME - 60
_max_hoster_reveal_time = MAX_HOSTER_REVEAL_TIME - 60

class Hoster:
    """
    The Hoster is responsible for participating in a decentralized inference protocol by:

    1. Listening for a random tensor generated by the validator at the start of the epoch.
    2. Running inference on that tensor using a local model (should be same model for each validator in this specific container use case).
    3. Committing a salted hash of the inference result to the DHT during the commit phase (usually first half) of the epoch.
    4. Revealing the full inference result along with the salt during the reveal phase (usually second half) of the same epoch.
        - The commit-reveal is validated by all nodes (see validator.py - Validator class)

    This commit-reveal scheme ensures that hosters cannot copy or fabricate others' outputs after seeing their commits.

    Args:
        dht (DHT): The DHT node for storing and retrieving data.
        inference_protocol (InferenceProtocol): Interface for running streaming inference on input tensors.
        record_validator (RecordValidatorBase): Keypair used for signing DHT records.
        hypertensor (Hypertensor): Hypertensor client config for accessing block and epoch info.
    """

    def __init__(
        self,
        dht: DHT,
        subnet_id: int,
        subnet_node_id: int,
        inference_protocol: InferenceProtocol,
        record_validator: RecordValidatorBase,
        hypertensor: Hypertensor,
        start: bool = True
    ):
        self.dht = dht
        self.subnet_id = subnet_id
        self.subnet_node_id = subnet_node_id
        self.peer_id = self.dht.peer_id
        self.inference_protocol = inference_protocol
        self.record_validator = record_validator
        self.hypertensor = hypertensor
        self.records_extension = 360
        self.epoch_length = int(str(self.hypertensor.get_epoch_length()))
        self.stop = threading.Event()

        if start:
            self.run()

    def run(self):
        asyncio.run(self.run_forever())

    async def run_forever(self):
        """
        Main loop:
         1. In the first half of each epoch, wait for the consensus tensor, run inference, commit.
         2. Wait until the second half of the same epoch, then reveal.
         3. Sleep until the next epoch begins, then repeat.
        """
        while not self.stop.is_set():
            current_block = self.hypertensor.get_block_number()
            current_epoch = current_block // self.epoch_length
            epoch_data = get_epoch_progress(current_block, current_epoch)
            percent = epoch_data.percent_complete

            result = None

            """
            Step 1: Wait for random prompt to be stored to DHT and commit in the first half of epoch
            """
            if percent <= 0.5:
                while not self.stop.is_set():
                    epoch_data = get_epoch_progress(current_block, current_epoch)
                    epoch = epoch_data.epoch
                    percent = epoch_data.percent_complete

                    # If we've moved into the second half without finding a tensor, break
                    if percent > 0.5:
                        break

                    # Run inference on random prompt
                    result = self.try_commit_inference(epoch)

                    # break if successful
                    if result:
                        break

                    # If commit unsuccessful the tensor may not be ready yet or storage unsuccessful
                    # Wait another block and try again
                    await asyncio.sleep(1.0)

            """
            Step 2: Wait until second half of epoch to reveal commit to DHT
            """
            while not self.stop.is_set():
                current_block = self.hypertensor.get_block_number()
                current_epoch = current_block // self.epoch_length
                epoch_data = get_epoch_progress(current_block, current_epoch)
                percent = epoch_data.percent_complete
                epoch = epoch_data.epoch

                if percent > 0.5:
                    break

                await asyncio.sleep(1.0)

            if self.last_inference is not None:
                print(f"[Hoster] revealing for epoch {epoch}")
                result = self.reveal(epoch, result)
            else:
                print(f"[Hoster] No inference result to reveal for epoch {epoch}")


            """
            Sleep until next epoch
            """
            epoch_data = self.hypertensor.get_epoch_progress()
            seconds_remaining = epoch_data.seconds_remaining

            await asyncio.sleep(
                max(0.0, seconds_remaining)
            )

            current_block = self.hypertensor.get_block_number()
            current_epoch = current_block // self.epoch_length
            blocks_until_next_epoch = ((current_epoch + 1) * self.epoch_length) - current_block
            seconds_until_next_epoch = blocks_until_next_epoch * BLOCK_SECS
            while not self.stop.is_set():
                await asyncio.sleep(seconds_until_next_epoch)
                if epoch != current_epoch:
                    break

    async def try_load_tensor(self, key: bytes, epoch: int) -> Optional[torch.Tensor]:
        """
        Load the validators random tensor for the epoch

        We expect the data to use the recore validator so we expect it to have a
        subkey using their public key and remove that from the value to extract
        the data
        """
        results = self.dht.get(key, latest=True)

        if results is None:
            return None
        try:
            """
            Get submitted torch.Tensor from the validator if exists, otherwise, the next
            """
            print("try_load_tensor results", results)

            validator = self.hypertensor.get_elected_validator_node(self.subnet_id, epoch)
            validator_peer_id = validator["peer_id"]

            first_prompt = None
            validator_prompt = None
            for public_key, data in results.value.items():
                value = data.value
                if first_prompt is None:
                    first_prompt = value

                peer_id = extract_rsa_peer_id(public_key)
                if peer_id is not None and validator_peer_id == peer_id:
                    validator_prompt = value
                    break

            data = validator_prompt or first_prompt

            return torch.load(io.BytesIO(data), weights_only=False)
        except Exception as e:
            logger.warning(f"Loading tensor failed with: {e}", exc_info=True)
            return None

    def model_commit_fn(self, tensor: torch.Tensor) -> Tuple[bytes, bytes]:
        """
        Create a salted SHA256 hash of the tensor.
        Returns (salt, hash).
        """
        buffer = io.BytesIO()
        torch.save(tensor, buffer)
        tensor_bytes = buffer.getvalue()

        salt = secrets.token_bytes(16)
        digest = hashlib.sha256(salt + tensor_bytes).digest()
        return salt, digest

    def commit(self, epoch: int, result: torch.Tensor):
        salt, digest = self.model_commit_fn(result)
        self.last_salt = salt
        self.last_inference = result
        result = self.dht.store(
            get_hoster_commit_key(epoch),
            digest,
            get_dht_time() + _max_hoster_commit_time,
            get_hoster_subkey_rsa(self.record_validator),
        )
        print("HosterV2 commit", result)
        logger.info(f"[Hoster] Committed hash for epoch {epoch}")
        return result

    def reveal(self, epoch: int, result: torch.Tensor):
        buffer = io.BytesIO()
        torch.save(result, buffer)
        payload = {
            "salt": self.last_salt,
            "tensor": buffer.getvalue(),
        }
        """
        asyncio.create_task(
            asyncio.wait_for(
                self.dht.store(
                    download_key,
                    subkey=self.peer_id.to_bytes(),
                    value=self.state_sharing_priority if self.allow_state_sharing else None,
                    expiration_time=expiration_time,
                    return_future=True,
                ),
                timeout=expiration_time - get_dht_time(),
            )
        )
        """
        result = self.dht.store(
            get_hoster_reveal_key(epoch),
            payload,
            get_dht_time() + _max_hoster_reveal_time,
            get_hoster_subkey_rsa(self.record_validator),
        )
        print("HosterV2 reveal", result)

        logger.info(f"[Hoster] Revealed reveal for epoch {epoch}")

        return result

    async def try_commit_inference(self, epoch: int):
        """
        Check for the consensus tensor and either commit or reveal based on epoch progress.
        """

        consensus_key = get_consensus_key(epoch)
        consensus_tensor = await self.try_load_tensor(consensus_key, epoch)
        if consensus_tensor is None:
            return False

        # Call inference on self
        inference_output = await self.inference_protocol.call_inference_stream(
            peer=self.peer_id,
            promt="",
            tensor=consensus_tensor
        )

        return self.commit(epoch, inference_output)

    def shutdown(self):
        self.stop.set()
